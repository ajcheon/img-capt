{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')\n",
    "ANNOT_PATH = Path('data/annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caption_index(annot_path, dataset='train', year=2017):\n",
    "    annot_file = annot_path/f'captions_{dataset}{year}.json'\n",
    "    return COCO(annot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.18s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco_train = get_caption_index(ANNOT_PATH, dataset='train')\n",
    "coco_val = get_caption_index(ANNOT_PATH, dataset='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(coco_api):\n",
    "    annot_keys = list(coco_api.anns.keys())\n",
    "    img_ids, img_paths, captions = [], [], []\n",
    "    for k in tqdm(annot_keys):\n",
    "        img_id = coco_api.anns[k]['image_id']\n",
    "        img_ids.append(coco_api.anns[k]['image_id'])\n",
    "        captions.append(coco_api.anns[k]['caption'])\n",
    "        img_paths.append(coco_api.loadImgs(img_id)[0]['file_name'])\n",
    "    df = pd.DataFrame({'img_id':img_ids, 'img_path':img_paths, 'caption':captions})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 591753/591753 [00:01<00:00, 385867.44it/s]\n",
      "100%|██████████| 25014/25014 [00:00<00:00, 325121.31it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train = get_df(coco_train)\n",
    "df_val = get_df(coco_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>179765</td>\n",
       "      <td>000000179765.jpg</td>\n",
       "      <td>A black Honda motorcycle parked in front of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>179765</td>\n",
       "      <td>000000179765.jpg</td>\n",
       "      <td>A Honda motorcycle parked in a grass driveway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>190236</td>\n",
       "      <td>000000190236.jpg</td>\n",
       "      <td>An office cubicle with four different types of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331352</td>\n",
       "      <td>000000331352.jpg</td>\n",
       "      <td>A small closed toilet in a cramped space.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>517069</td>\n",
       "      <td>000000517069.jpg</td>\n",
       "      <td>Two women waiting at a bench next to a street.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25009</th>\n",
       "      <td>9590</td>\n",
       "      <td>000000009590.jpg</td>\n",
       "      <td>A group of men sipping drinks and talking at a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25010</th>\n",
       "      <td>84664</td>\n",
       "      <td>000000084664.jpg</td>\n",
       "      <td>A plate of food with some eggs, potatoes, brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25011</th>\n",
       "      <td>331569</td>\n",
       "      <td>000000331569.jpg</td>\n",
       "      <td>The strawberries was sitting beside the tall g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25012</th>\n",
       "      <td>231237</td>\n",
       "      <td>000000231237.jpg</td>\n",
       "      <td>A bunch of small red flowers in a barnacle enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25013</th>\n",
       "      <td>386134</td>\n",
       "      <td>000000386134.jpg</td>\n",
       "      <td>Food is in a styrofoam take out container.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25014 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       img_id          img_path  \\\n",
       "0      179765  000000179765.jpg   \n",
       "1      179765  000000179765.jpg   \n",
       "2      190236  000000190236.jpg   \n",
       "3      331352  000000331352.jpg   \n",
       "4      517069  000000517069.jpg   \n",
       "...       ...               ...   \n",
       "25009    9590  000000009590.jpg   \n",
       "25010   84664  000000084664.jpg   \n",
       "25011  331569  000000331569.jpg   \n",
       "25012  231237  000000231237.jpg   \n",
       "25013  386134  000000386134.jpg   \n",
       "\n",
       "                                                 caption  \n",
       "0      A black Honda motorcycle parked in front of a ...  \n",
       "1          A Honda motorcycle parked in a grass driveway  \n",
       "2      An office cubicle with four different types of...  \n",
       "3              A small closed toilet in a cramped space.  \n",
       "4         Two women waiting at a bench next to a street.  \n",
       "...                                                  ...  \n",
       "25009  A group of men sipping drinks and talking at a...  \n",
       "25010  A plate of food with some eggs, potatoes, brea...  \n",
       "25011  The strawberries was sitting beside the tall g...  \n",
       "25012  A bunch of small red flowers in a barnacle enc...  \n",
       "25013         Food is in a styrofoam take out container.  \n",
       "\n",
       "[25014 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
