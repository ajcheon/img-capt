{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')\n",
    "ANNOT_PATH = PATH/'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annot_index(annot_path, dataset='train', year=2017):\n",
    "    annot_file = annot_path/f'captions_{dataset}{year}.json'\n",
    "    return COCO(annot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embeddings and vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from class demo notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_glove():\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "    ! mkdir data\n",
    "    ! unzip glove.6B.zip -C data\n",
    "\n",
    "def loadGloveModel(gloveFile=PATH/\"glove.6B.50d.txt\"):\n",
    "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    return word_vecs\n",
    "\n",
    "def get_word_count(content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(float)\n",
    "    for line in content:\n",
    "        words = set(line.split())\n",
    "        for word in words:\n",
    "            counts[word] += 1\n",
    "    return counts\n",
    "\n",
    "def delete_rare_words(word_vecs, word_count, min_df=5):\n",
    "    \"\"\" Deletes rare words from word_count\n",
    "    \n",
    "    Deletes words from word_count if they are not in word_vecs\n",
    "    and don't have at least min_df occurrencies in word_count.\n",
    "    \"\"\"\n",
    "    words_delete = []\n",
    "    for word in word_count:\n",
    "        if word_count[word] < min_df and word not in word_vecs:\n",
    "            words_delete.append(word)\n",
    "    for word in words_delete: word_count.pop(word)\n",
    "    return word_count\n",
    "\n",
    "def create_embedding_matrix(word_vecs, word_count, min_df=4, emb_size=50):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    word_count = delete_rare_words(word_vecs, word_count, min_df)\n",
    "    extra_words = [\"<pad>\", \"<unk>\", \"<start>\", \"<end>\"]\n",
    "    vocab_len = len(word_count.keys()) + len(extra_words)\n",
    "    W = np.zeros((vocab_len, emb_size), dtype=\"float32\")\n",
    "    \n",
    "    # adding a vector for padding\n",
    "    W[0] = np.zeros(emb_size, dtype='float32')\n",
    "    # adding a vector for rare words \n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    # adding vectors for <start>, <end> tokens\n",
    "    W[2] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    W[3] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    \n",
    "    vocab2index = {word : i for i, word in enumerate(extra_words)}\n",
    "    vocab = extra_words\n",
    "    i = len(vocab)\n",
    "    for word in word_count:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab2index[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1\n",
    "    return W, np.array(vocab), vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = get_annot_index(ANNOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.77s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = get_annot_index(ANNOT_PATH)\n",
    "annot_ids = coco.anns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 591753/591753 [00:00<00:00, 1902873.39it/s]\n"
     ]
    }
   ],
   "source": [
    "all_captions = [str(coco.anns[id]['caption']) for id in tqdm(annot_ids)]\n",
    "word_count = get_word_count(all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = loadGloveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 53155\n"
     ]
    }
   ],
   "source": [
    "print(len(word_vecs), len(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24178"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = delete_rare_words(word_vecs, word_count, min_df=10)\n",
    "len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights, vocab, vocab2index = create_embedding_matrix(word_vecs, word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.24465083, -0.11952231, -0.20686829, ...,  0.22003843,\n",
       "         0.05354511, -0.21504742],\n",
       "       [-0.03769932, -0.1310914 ,  0.0603082 , ..., -0.01164583,\n",
       "         0.12908918,  0.1663074 ],\n",
       "       ...,\n",
       "       [ 0.11737   ,  0.25231   ,  0.071165  , ..., -0.94342   ,\n",
       "         0.71416   ,  0.45284   ],\n",
       "       [-0.12779   , -0.049853  , -0.77253   , ...,  0.7053    ,\n",
       "         0.79276   ,  0.090612  ],\n",
       "       [-0.99742   ,  0.25117   , -0.02051   , ...,  0.024489  ,\n",
       "        -0.71593   ,  1.5538    ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<pad>', '<unk>', '<start>', '<end>', 'a', 'bicycle', 'replica',\n",
       "       'with', 'clock', 'as', 'the', 'front', 'wheel', '.', 'room',\n",
       "       'blue', 'walls', 'and', 'white', 'sink'], dtype='<U18')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img-capt",
   "language": "python",
   "name": "img-capt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
