{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.1.tar.gz (23 kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pycocotools) (46.1.3.post20200330)\n",
      "Requirement already satisfied: cython>=0.27.3 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pycocotools) (0.29.15)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pycocotools) (3.1.3)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools) (1.14.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.1-cp36-cp36m-linux_x86_64.whl size=280629 sha256=bcc9801420aa65263a5c51b6fbe9a7d5d20c208582a4309a3be6dee0e42178c9\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/3f/ef/f8/0335de365305b04082b274251f59bdc6805238a9fe33cc17ae\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data')\n",
    "ANNOT_PATH = PATH/'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annot_index(annot_path, dataset='train', year=2017):\n",
    "    annot_file = annot_path/f'captions_{dataset}{year}.json'\n",
    "    return COCO(annot_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove embeddings and vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapted from class demo notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_glove():\n",
    "    ! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "    ! mkdir data\n",
    "    ! unzip glove.6B.zip -C data\n",
    "\n",
    "def loadGloveModel(gloveFile=PATH/\"glove.6B.50d.txt\"):\n",
    "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
    "    f = open(gloveFile,'r')\n",
    "    word_vecs = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
    "    return word_vecs\n",
    "\n",
    "def get_word_count(content):\n",
    "    \"\"\"Computes Dict of counts of words.\n",
    "    \n",
    "    Computes the number of times a word is on a document.\n",
    "    \"\"\"\n",
    "    counts = defaultdict(float)\n",
    "    for line in content:\n",
    "        words = set(line.split())\n",
    "        for word in words:\n",
    "            counts[word] += 1\n",
    "    return counts\n",
    "\n",
    "def delete_rare_words(word_vecs, word_count, min_df=5):\n",
    "    \"\"\" Deletes rare words from word_count\n",
    "    \n",
    "    Deletes words from word_count if they are not in word_vecs\n",
    "    and don't have at least min_df occurrencies in word_count.\n",
    "    \"\"\"\n",
    "    words_delete = []\n",
    "    for word in word_count:\n",
    "        if word_count[word] < min_df and word not in word_vecs:\n",
    "            words_delete.append(word)\n",
    "    for word in words_delete: word_count.pop(word)\n",
    "    return word_count\n",
    "\n",
    "def create_embedding_matrix(word_vecs, word_count, min_df=4, emb_size=50):\n",
    "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
    "    word_count = delete_rare_words(word_vecs, word_count, min_df)\n",
    "    extra_words = [\"<pad>\", \"<unk>\", \"<start>\", \"<end>\"]\n",
    "    vocab_len = len(word_count.keys()) + len(extra_words)\n",
    "    W = np.zeros((vocab_len, emb_size), dtype=\"float32\")\n",
    "    \n",
    "    # adding a vector for padding\n",
    "    W[0] = np.zeros(emb_size, dtype='float32')\n",
    "    # adding a vector for rare words \n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    # adding vectors for <start>, <end> tokens\n",
    "    W[2] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    W[3] = np.random.uniform(-0.25, 0.25, emb_size)\n",
    "    \n",
    "    vocab2index = {word : i for i, word in enumerate(extra_words)}\n",
    "    vocab = extra_words\n",
    "    i = len(vocab)\n",
    "    for word in word_count:\n",
    "        if word in word_vecs:\n",
    "            W[i] = word_vecs[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab2index[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1\n",
    "    return W, np.array(vocab), vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.43s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = get_annot_index(ANNOT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.1.8)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (7.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.2.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.2.4)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from spacy) (0.1.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.44.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = get_annot_index(ANNOT_PATH)\n",
    "annot_ids = coco.anns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 591753/591753 [00:00<00:00, 1109052.06it/s]\n"
     ]
    }
   ],
   "source": [
    "all_captions = [str(coco.anns[id]['caption']) for id in tqdm(annot_ids)]\n",
    "word_count = get_word_count(all_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = loadGloveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 53155\n"
     ]
    }
   ],
   "source": [
    "print(len(word_vecs), len(word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24178"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = delete_rare_words(word_vecs, word_count, min_df=10)\n",
    "len(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights, vocab, vocab2index = create_embedding_matrix(word_vecs, word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<pad>', '<unk>', '<start>', '<end>', 'replica', 'a', 'wheel.',\n",
       "       'bicycle', 'A', 'the', 'front', 'clock', 'as', 'with', 'door.',\n",
       "       'white', 'walls', 'sink', 'room', 'and'], dtype='<U19')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pretrained_weights, open(PATH/'pretrained_weights.pkl', 'wb'))\n",
    "pickle.dump(vocab, open(PATH/'vocab.pkl', 'wb'))\n",
    "pickle.dump(vocab2index, open(PATH/'vocab2index.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
